{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Estimate left-pose of an image.\n",
        "(Provide image from a dataset for a reference.)"
      ],
      "metadata": {
        "id": "yfOUwOXdvxE3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew70DSbfvuq5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def detect_features(image):\n",
        "    \"\"\"Detect keypoints and descriptors in the image using ORB.\"\"\"\n",
        "    orb = cv2.ORB_create()\n",
        "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
        "    return keypoints, descriptors\n",
        "\n",
        "def match_features(descriptors1, descriptors2):\n",
        "    \"\"\"Match features using BFMatcher.\"\"\"\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "    matches = bf.match(descriptors1, descriptors2)\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "    return matches\n",
        "\n",
        "def estimate_pose(matches, keypoints1, keypoints2, K):\n",
        "    \"\"\"Estimate the pose using solvePnP.\"\"\"\n",
        "    if len(matches) < 4:\n",
        "        raise ValueError(\"Not enough matches to estimate pose.\")\n",
        "\n",
        "    # Extract matched keypoints\n",
        "    pts1 = np.float32([keypoints1[m.queryIdx].pt for m in matches])\n",
        "    pts2 = np.float32([keypoints2[m.trainIdx].pt for m in matches])\n",
        "\n",
        "    # Define corresponding 3D points (assuming some fixed depth or using a known pattern)\n",
        "    # In practice, you would use actual 3D coordinates of the matched points\n",
        "    obj_points = np.float32([[p[0], p[1], 0] for p in pts1])\n",
        "\n",
        "    # Assume the camera matrix (intrinsic parameters)\n",
        "    camera_matrix = K\n",
        "    dist_coeffs = np.zeros(4)  # assuming no lens distortion\n",
        "\n",
        "    success, rvec, tvec = cv2.solvePnP(obj_points, pts2, camera_matrix, dist_coeffs)\n",
        "\n",
        "    if not success:\n",
        "        raise ValueError(\"Pose estimation failed.\")\n",
        "\n",
        "    # Convert rotation vector to rotation matrix\n",
        "    R, _ = cv2.Rodrigues(rvec)\n",
        "\n",
        "    # Construct the pose matrix\n",
        "    pose = np.eye(4)\n",
        "    pose[:3, :3] = R\n",
        "    pose[:3, 3] = tvec[:, 0]\n",
        "\n",
        "    return pose\n",
        "\n",
        "def get_left_pose(image_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n",
        "\n",
        "    # Assume we have a reference image for matching\n",
        "    reference_image = image\n",
        "\n",
        "    # Detect features in both images\n",
        "    kp1, des1 = detect_features(image)\n",
        "    kp2, des2 = detect_features(reference_image)\n",
        "\n",
        "    # Match features\n",
        "    matches = match_features(des1, des2)\n",
        "\n",
        "    # Assume a dummy camera intrinsic matrix for pose estimation\n",
        "    K = np.array([[800, 0, image.shape[1]//2],\n",
        "                  [0, 800, image.shape[0]//2],\n",
        "                  [0, 0, 1]], dtype=np.float32)\n",
        "\n",
        "    # Estimate pose\n",
        "    left_pose = estimate_pose(matches, kp1, kp2, K)\n",
        "\n",
        "    return left_pose\n",
        "\n",
        "# Example usage:\n",
        "image_path = '/content/stcg.us.0003_f8f1f2c0b57a4d9981ef602f99030def_cam-1_change-1.png'\n",
        "left_pose = get_left_pose(image_path)\n",
        "print(\"Left Pose:\\n\", left_pose)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimate right-pose of an image.\n",
        "(Provide image from a dataset for a reference.)"
      ],
      "metadata": {
        "id": "9VKiR3pSv7-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def detect_features(image):\n",
        "    \"\"\"Detect keypoints and descriptors in the image using ORB.\"\"\"\n",
        "    orb = cv2.ORB_create()\n",
        "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
        "    return keypoints, descriptors\n",
        "\n",
        "def match_features(descriptors1, descriptors2):\n",
        "    \"\"\"Match features using BFMatcher.\"\"\"\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "    matches = bf.match(descriptors1, descriptors2)\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "    return matches\n",
        "\n",
        "def estimate_pose(matches, keypoints1, keypoints2, K):\n",
        "    \"\"\"Estimate the pose using solvePnP.\"\"\"\n",
        "    if len(matches) < 4:\n",
        "        raise ValueError(\"Not enough matches to estimate pose.\")\n",
        "\n",
        "    # Extract matched keypoints\n",
        "    pts1 = np.float32([keypoints1[m.queryIdx].pt for m in matches])\n",
        "    pts2 = np.float32([keypoints2[m.trainIdx].pt for m in matches])\n",
        "\n",
        "    # Define corresponding 3D points (assuming some fixed depth or using a known pattern)\n",
        "    # In practice, you would use actual 3D coordinates of the matched points\n",
        "    obj_points = np.float32([[p[0], p[1], 0] for p in pts1])\n",
        "\n",
        "    # Assume the camera matrix (intrinsic parameters)\n",
        "    # For example purposes, we use a simple camera matrix\n",
        "    camera_matrix = K\n",
        "    dist_coeffs = np.zeros(4)  # assuming no lens distortion\n",
        "\n",
        "    success, rvec, tvec = cv2.solvePnP(obj_points, pts2, camera_matrix, dist_coeffs)\n",
        "\n",
        "    if not success:\n",
        "        raise ValueError(\"Pose estimation failed.\")\n",
        "\n",
        "    # Convert rotation vector to rotation matrix\n",
        "    R, _ = cv2.Rodrigues(rvec)\n",
        "\n",
        "    # Construct the pose matrix\n",
        "    pose = np.eye(4)\n",
        "    pose[:3, :3] = R\n",
        "    pose[:3, 3] = tvec[:, 0]\n",
        "\n",
        "    return pose\n",
        "\n",
        "def get_right_pose(image_path, reference_image_path):\n",
        "    # Load the images\n",
        "    image = cv2.imread(image_path)\n",
        "    reference_image = cv2.imread(reference_image_path)\n",
        "\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n",
        "\n",
        "    if reference_image is None:\n",
        "        raise ValueError(f\"Reference image at path {reference_image_path} could not be loaded.\")\n",
        "\n",
        "    # Detect features in both images\n",
        "    kp1, des1 = detect_features(image)\n",
        "    kp2, des2 = detect_features(reference_image)\n",
        "\n",
        "    # Match features\n",
        "    matches = match_features(des1, des2)\n",
        "\n",
        "    # Assume a dummy camera intrinsic matrix for pose estimation\n",
        "    K = np.array([[800, 0, image.shape[1]//2],\n",
        "                  [0, 800, image.shape[0]//2],\n",
        "                  [0, 0, 1]], dtype=np.float32)\n",
        "\n",
        "    # Estimate pose\n",
        "    right_pose = estimate_pose(matches, kp1, kp2, K)\n",
        "\n",
        "    return right_pose\n",
        "\n",
        "# Example usage:\n",
        "image_path = '/content/stcg.us.0003_f8f1f2c0b57a4d9981ef602f99030def_cam-1_change-10001.png'\n",
        "reference_image_path = '/content/stcg.us.0003_f8f1f2c0b57a4d9981ef602f99030def_cam-1_change-1.png'\n",
        "right_pose = get_right_pose(image_path, reference_image_path)\n",
        "print(\"Right Pose:\\n\", right_pose)"
      ],
      "metadata": {
        "id": "N-d7Zx8Yv9yu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}